{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4C_hWFniZKBC",
        "hfebj9BmZwCz",
        "h26Evwh6mjWk",
        "vJ8JIgv8aQEY",
        "dyIQj7Qz4w_I",
        "bKz5Aiv_5DCv",
        "gxVn4DXWZxnn",
        "Y_ekugvFZ37H",
        "akgczqvuHItd",
        "TLkhX_Bn7cPb",
        "AvV_WlkLHZwX",
        "A2vr4zCbL6k5",
        "z_i2BoHIGRTw",
        "QJ3cZ_uY76YK",
        "cocCMmqn9GYA",
        "YwyXF6b4HPVX",
        "aWJgF8Juht5J",
        "37aNXKq8h83Y",
        "1Sg4bcS8rsff",
        "FTt-8rWLkbIP",
        "051R_DSAtUeq",
        "43kgH_lawEhq",
        "VCjVX6GwFt9C",
        "Ktdhydb4BjsK",
        "6zWPZoChwKLb",
        "fhPvkAgTlMSX",
        "_rfxH7SaGE3V",
        "4x1-f3R6qVNk",
        "YMa4kLQyzLHL",
        "YU7-dom3RXU1",
        "wXFQfeYGEQ6u",
        "wVaMF7EwcrEf",
        "_HmIXxhACViM",
        "RFPJtY2DCUkG",
        "GwdohL9WBrV8",
        "CjlGD0EUB-t-",
        "JqE_LMrJbp8N",
        "xcjBl0UUbp8j",
        "foF8_0Rvj2S-",
        "JQE3_O-Am_wg",
        "GWAK3FJ3BtpM",
        "BtiILJ-WZJjl",
        "pZnyTegKYamy",
        "iK6F2mQAZoM9",
        "9HwRuiyUj-FV",
        "3u9QK5rQkQPu",
        "bmvuRochzfBa",
        "MmVvEo6Lk5Jx",
        "gzsTYRfUnGjD",
        "wN1zEZmlnShn",
        "worJF5-jnLXR",
        "6xXo8cRBWv7w",
        "Kv5tIBsdRWJH",
        "4U5oylveuGRT",
        "wssYm7s9up2v",
        "Fl9yCbnyVuC4",
        "rE1c7IFHO_6X",
        "nU9HepnQOhLb",
        "sbo88KqPPqKe",
        "4JtugSrsOhLc",
        "0V5aDl07OhLj",
        "OsBf4HkPQuuE",
        "GrA4LDeAQqXh",
        "_Rw8pkDsSf5N",
        "HEiF_bdbRxcM",
        "8NbxaQOZRq8g"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpazerf/kaggle/blob/main/Kaggle_Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C_hWFniZKBC"
      },
      "source": [
        "# Business Data Science: Kaggle Competition\n",
        "\n",
        "\n",
        "Name: Harris Azerf\n",
        "\n",
        "Kaggle Username: Harris Azerf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQrf4j9BA_o3"
      },
      "source": [
        "## Code Breakdown and Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ErRTiDeBUqU"
      },
      "source": [
        "### Quick Description\n",
        "***\n",
        "While looking at the code and breaking it down to sections, the first section looked at the Raw Data with no manipulation. The second section removed the Id column. The third focused on standardizing the data. The last section looked at feature importance and using the models. I used Google Colab to run all the code to make use of the GPU for certain models. After each model I placed the Kaggle Public AUC score to keep track of the different models and different levels of success I had for each of the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ECF0TgyBZJT"
      },
      "source": [
        "### Setup\n",
        "***\n",
        "This is where I imported all the libraries and the data for the models. For the data, I simply imported the data and then manipulated it to remove the id column. Also, I concatenated the two data sets together and standardized the features to use in the different models. This gave 3 different types of data sets to use for the models. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsNFkU-LBcL_"
      },
      "source": [
        "### Section 1: Raw Data using different models\n",
        "***\n",
        "The models I looked at where the baseline Logistic Regression, Random Forest, and XGBoost Models. These models used the data straight from the csv files to create the models and predict the probabilities. This section was broken down into one subsection called **No Tuning**. The subsection, **No Tuning**, was broken down into sections for each different model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAQdTSZ6BevP"
      },
      "source": [
        "### Section 2: Data without Id Column\n",
        "***\n",
        "After a small confusion that I explain below, I removed the Id column and looked at the Random Forest, Xgboost, Catboost, and Light GB models. I tried all of these models without any tuning initially. Then, I tuned each model with different parameter ranges to help with overfitting and creating different results. The best result that I was able to get using these models was the Catboost. I also attempted to try stacking using different models but end up with models that overfit the test data. \n",
        "\n",
        "Initially, when I started using the dataset without the Id column there was some confusion. When I ran this the first few times, I made a mistake in thinking I standardized the data which I initially did, but due to some mishap I unknowingly  deleted the portion that standardized the data. Later when looking back at how I standardized, I realized I only removed the Id column and not actually standardizing the data. After I realized this I fixed the variables to represent this mistake.\n",
        "\n",
        "This section was split into subsections for **No Tuning**, **Tuning**, **Tuned Models**, and **Stacking**. For each of these sections I looked at the models mentioned above. In the **No Tuning** section, I used the baseline model to see how each model performed with no tuning. In the **Tuning** section, I tuned and obtained different parameters using GridSearchCV and RandomSearchCV. For each model, I came back multiple times and set different ranges and parameters based on different resources that I found. The parameters that I found in **Tuning** were used in the **Tuned Models** sections breaking down the success of each model. In the **Stacking** section, I also tried stacking several of the models in several different ways to hopefully get a better result. Most of the models that I stacked resulted in a lower score. I believe this occurred  due to overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UfcWLvPBhy7"
      },
      "source": [
        "### Section 3: Standardized Data\n",
        "***\n",
        "In this section, I standardized  the data and then tried tuning similar to what I did in the models above. The models I looked at where XGBoost, Random Forest, and Catboost. During this time, I tried to improve the XGBoost model as much as I could. I also tried tuning the Random forest and Catboost without much success.\n",
        "\n",
        "This section was split into subsections for **No Tuning**, **Tuning**, and **Tuned Models**. I did similar things to what I did above to where I started with the baseline models and the moved to tuning the parameters for each of classifiers using GridSearchCV and RandomSearchCV. Similar to above, I created different ranges of parameters to help create multiple slightly different models. During this time, I focused heavily on XGboost and improving that score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDf5TwJ7BjqD"
      },
      "source": [
        "### Section 4: Feature Selection\n",
        "***\n",
        "In this section, I dropped some of the features by using feature importance for each of the different models, mainly focusing on XGBoost, Catboost, and Light GB. I went through the same process of tuning with slightly different ranges to improve the score. I also tried stacking the models again to see if I can get a better result. During this part, I used Catboost and dropped a few features to get the best overall results.\n",
        "\n",
        "This section is split based on the classifier and dataset that was being used. I used **XGBoost with the Standardized Values**, **CatBoost with the Standardized Values**, **CatBoost with Data with No Id column**, and **Light GB with Data with No Id column**. Each of these subsections are broken down even further. First, I find the importance of features using a baseline model and the feature_importance method. Based on this, I remove the features with low importance. Then I tuned each model to find the best parameters and used those parameters to create several tuned models. As mentioned above, I also tried stacking which I placed into **XGBoost stacked with XGBoost**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UloPZe7xW1ca"
      },
      "source": [
        "## Model Testing Order\n",
        "***\n",
        "Overall, I started by looking at the baseline models for a few of the different classifiers which was mainly the Random Forest, XGBoost, and Catboost. For each of these models I tried various things such as tuning, stacking, parameter changes, and feature selection. The one I initially focused on was XGBoost since it gave me the highest AUC score initially. After dropping several unimportant features and improving the score as much as possible, I moved to looking at Catboost. Using Catboost, I was able to get my best score by once again dropping features and trying different parameters. Lastly, through my research I ran across Light GB model and tried the same methods that I used for both XGboost and Catboost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPV4BfBOafdZ"
      },
      "source": [
        "## What I learned\n",
        "***\n",
        "Different datasets worked better for different classifiers. For XGBoost, the standardized data worked best for my models, but when I used Catboost, the regular data worked better. In fact, my best score was Catboost using the regular data with a few features dropped. \n",
        "\n",
        "Also, during my research I read that having a high number of iterations helps prevent overfitting. To help prevent overfitting in most of the models, I used iterations from around 1000-2000. \n",
        "\n",
        "Looking back, stacking did not help me at all. This could be because the model was overfitting the data. \n",
        "\n",
        "Initially, I thought the Light GB models could help improve my score, but I think I did not tune the model well enough to get a better score.\n",
        "\n",
        "Feature Selection helped me improve my score every time after I hit a bump in tuning the models. It did not help when using Catboost with the standardized data, but it helped both for XGBoost using the standardized data and Catboost using the regular data. Both for XGBoost classifier and Catboost classifier, I was able to get the highest score in the public leaderboard by dropping several of the features. But looking back at the private leaderboard, the original models without any features drop performed better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCo7F4H3BOro"
      },
      "source": [
        "## Best Model\n",
        "***\n",
        "\n",
        "*Public Leaderboard:* For the Public Leaderboard, the best model I was able to create was a tuned Catboost with several features dropped. I took a baseline Catboost model and measured the feature importance of each feature and dropped those that had low values. After dropping the features, I tuned the model to find the best parameters based on the data with the dropped features. Using these parameters, I created the model that I was able to get the highest AUC score on the public leaderboard.\n",
        "\n",
        "*Private Leaderboard:* For the Private Leaderboard, I found that the models with the dropped features did worse than the models with all of the features in the data. The best model I created was a tuned Catboost using the complete regular data without any normalization and no dropped features. \n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h26Evwh6mjWk"
      },
      "source": [
        "# Setup\n",
        "\n",
        "\n",
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zftkLlgIY34K",
        "outputId": "89f94ce8-d43c-4aa8-f55c-a25481038d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip install xgboost\n",
        "!pip install catboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8JIgv8aQEY"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSzjUg7GaT3R"
      },
      "source": [
        "train = pd.read_csv('train_final.csv')\n",
        "test = pd.read_csv('test_final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmaxHNvP8uET",
        "outputId": "d7cd5a8e-c891-4a2b-e2b9-73f6051da0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16383, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh53KKT5arQB"
      },
      "source": [
        "y = train['Y']\n",
        "X = train.drop('Y', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWzKEb7tF-wd"
      },
      "source": [
        "### Standarizing the data and removing the Id Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx6H3yxwFqyF"
      },
      "source": [
        "# Combining all the data together\n",
        "all_data = pd.concat((train.loc[:,'f1':'f24'],\n",
        "                      test.loc[:,'f1':'f24']))\n",
        "feature_col_names=list(all_data.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJQtaLVzkyl7"
      },
      "source": [
        "# Removing Id Column\n",
        "all_data = pd.concat((train.loc[:,'f1':'f24'],\n",
        "                      test.loc[:,'f1':'f24']))\n",
        "X_no_id = all_data[:train.shape[0]]\n",
        "test_no_id = all_data[train.shape[0]:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZapmH7pFgZR"
      },
      "source": [
        "# Standarizing the data\n",
        "sc = StandardScaler()\n",
        "std=sc.fit_transform(all_data)\n",
        "\n",
        "#creating matrices for sklearn:\n",
        "X_std = std[:train.shape[0]]\n",
        "X_std = pd.DataFrame(data=X_std, columns=feature_col_names)\n",
        "test_std = std[train.shape[0]:]\n",
        "test_std = pd.DataFrame(data=test_std, columns=feature_col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyIQj7Qz4w_I"
      },
      "source": [
        "# S1: Raw Data using different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKz5Aiv_5DCv"
      },
      "source": [
        "## S1-A: No Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxVn4DXWZxnn"
      },
      "source": [
        "### Logisitic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xedMY5VUbAE9",
        "outputId": "c5126479-0f2d-4443-f608-12da58e7f942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr = LogisticRegression(random_state = 42)\n",
        "lr.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22h_nClbZ2rW",
        "outputId": "1699bdb8-1391-4ba3-f918-1368a2538f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_pred = lr.predict(X)\n",
        "y_probas = lr.predict_proba(X)\n",
        "print('Misclassified samples: %d' %(y != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y, y_pred))\n",
        "print('AUC: %.2f' % roc_auc_score(y, y_probas[:, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 948\n",
            "Accuracy: 0.94\n",
            "AUC: 0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mELoX74y3cT-"
      },
      "source": [
        "test_probas = lr.predict_proba(test)\n",
        "lr_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "lr_solution.to_csv(\"lr_no_std_no_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVN-1xX6GzLs"
      },
      "source": [
        "Kaggle Score: 0.54023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_ekugvFZ37H"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvEFMRB3Z6Ga",
        "outputId": "57ca8138-e6ab-4f75-9a7e-dd14d987d433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs = -1,random_state = 42)\n",
        "rf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rygzXADiDAp"
      },
      "source": [
        "test_probas = rf.predict_proba(test)\n",
        "rf_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "rf_solution.to_csv(\"rf_no_std_no_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpCwXGJIG8zJ"
      },
      "source": [
        "Kaggle Score: 0.84233"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akgczqvuHItd"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PePCIuSl8B3t"
      },
      "source": [
        "xgb_model = XGBClassifier(n_estimators=1000, random_state=42)\n",
        "xgb_model.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq0QL6EO6SeG"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std2_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVKtM8FJ6ap1"
      },
      "source": [
        "Kaggle Score: 0.86479"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qparuo2MA_pc"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aii6WpcO6ie2"
      },
      "source": [
        "# S2: Data without Id Column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLkhX_Bn7cPb"
      },
      "source": [
        "## S2-A: No Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvV_WlkLHZwX"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFK0E2AHZwY",
        "outputId": "cfa05901-b6d4-4d3e-9fef-8157c8cd3186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrXL2f9HZwe"
      },
      "source": [
        "test_probas = rf.predict_proba(test_no_id)\n",
        "rf_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "rf_solution.to_csv(\"rf_std_no_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nBxOI_EHZwg"
      },
      "source": [
        "Kaggle Score: 0.86222"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2vr4zCbL6k5"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tXrwq7hL6lJ"
      },
      "source": [
        "xgb_model = XGBClassifier(max_depth=10,min_child_weight=1,gamma=1,scale_pos_weight=.6,subsample=0.5,n_estimators=1000, random_state=42)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avNuaJ0nL6lO"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_no_id)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std_no_tuning_no_param_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDuWeT8SpGkj"
      },
      "source": [
        "Kaggle Score: 0.87718"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_i2BoHIGRTw"
      },
      "source": [
        "### Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlV5XtTqGRTx"
      },
      "source": [
        "cb_model = CatBoostClassifier(lograndom_state=42,task_type='GPU', verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoH8DsBmGRT3"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_std_no_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad2GgwNVGRT5"
      },
      "source": [
        "Kaggle Score: 0.86237"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UZ-1lIZP44w"
      },
      "source": [
        "### Light GB Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOAq25b8A5f",
        "outputId": "d2780b59-3b19-45cb-e42d-477247a747a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "lgb_model = LGBMClassifier(metric='auc',random_state=42, n_estimators=1500, verbose=0)\n",
        "lgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
              "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
              "               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,\n",
              "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
              "               subsample_freq=0, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz4CtW9uImOc"
      },
      "source": [
        "test_probas = lgb_model.predict_proba(test_no_id)\n",
        "lgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "lgb_solution.to_csv(\"lgb_model_noid_no_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDmM7ZJfQ5Qu"
      },
      "source": [
        "Kaggle Score: 0.86656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ3cZ_uY76YK"
      },
      "source": [
        "## S2-B: Tuning Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cocCMmqn9GYA"
      },
      "source": [
        "### Tuning the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vruZqhMA9NV_",
        "outputId": "c735ef75-b991-44ad-8a3e-3cf9b30ccead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjJARcof9avV",
        "outputId": "ab83241a-4189-4bd8-8347-f1692901b90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hypertuning the Random Forest Model\n",
        "\n",
        "# Number of trees in random forest\n",
        "#n_estimators = [500,1000,1500,2000]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {#'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap\n",
        "               }\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, scoring='roc_auc', cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_no_id, y)\n",
        "# print results\n",
        "print(rf_random.best_params_)\n",
        "print(rf_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   51.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
            "0.8615652409245795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwyXF6b4HPVX"
      },
      "source": [
        "### Tuning the XGBoost\n",
        "Due to the many variables to tune, I separated them into different sections by slowly building the model to get a quick range of where all the parameters were. Then I created a smaller grid search that looked at the smaller range for all the variables. I ran this multiple times with slightly different  ranges to get two or three different models to test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWJgF8Juht5J"
      },
      "source": [
        "#### Tuning the eta and max_depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9h8FLeAN3Ik",
        "outputId": "52fb5e7c-1f24-45c2-dc9b-1b7059af523a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcQ59NMscjiG",
        "outputId": "74102576-3e62-4d2d-a49f-8c30f6173592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "max_depth=[1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# Create the random grid\n",
        "grid = {\n",
        "        'max_depth': max_depth,\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_search = GridSearchCV(estimator = xgb_model, param_grid = grid, cv = 5, scoring='roc_auc', verbose=2, n_jobs = -1)\n",
        "# Fit the model\n",
        "xgb_search.fit(X_no_id, y)\n",
        "# print results\n",
        "print(xgb_search.best_params_)\n",
        "print(xgb_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   54.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 6}\n",
            "0.8555425240205217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37aNXKq8h83Y"
      },
      "source": [
        "#### Tuning the min_child_weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dif7aOx5h0DI",
        "outputId": "af490b3a-5df5-4dfe-a03a-9a04c0393406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4,max_depth=6, random_state=42)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eta=0.4, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF49WhW_Ns5W",
        "outputId": "79b4b9d7-d201-4e69-fca6-4f030190ab4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "min_child_weight=[1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "\n",
        "# Create the random grid\n",
        "grid = {\n",
        "        'min_child_weight': min_child_weight,\n",
        "\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_search = GridSearchCV(estimator = xgb_model, param_grid = grid, cv = 5, scoring='roc_auc', verbose=2, n_jobs = -1)\n",
        "# Fit the model\n",
        "xgb_search.fit(X_no_id, y)\n",
        "# print results\n",
        "print(xgb_search.best_params_)\n",
        "print(xgb_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'min_child_weight': 6}\n",
            "0.8575492595361996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sg4bcS8rsff"
      },
      "source": [
        "#### Tuning the gamma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTDDbqJXrX_p"
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4,max_depth=6,min_child_weight=6, random_state=42)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMLuIZBrVhO"
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "gamma=[1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# Create the random grid\n",
        "grid = {\n",
        "        'gamma': gamma,\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_search = GridSearchCV(estimator = xgb_model, param_grid = grid, cv = 5, scoring='roc_auc', verbose=2, n_jobs = -1)\n",
        "# Fit the model\n",
        "xgb_search.fit(X_no_id, y)\n",
        "# print results\n",
        "print(xgb_search.best_params_)\n",
        "print(xgb_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTt-8rWLkbIP"
      },
      "source": [
        "#### Tuning the subsample and the scale_pos_weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EmvGLPZkarp",
        "outputId": "4240b174-a20a-4902-d536-d889c42eabab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4,max_depth=6,min_child_weight=6,gamma=4, random_state=42)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eta=0.4, gamma=4,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=6, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bja7za51mckj",
        "outputId": "d8b72d86-56d6-429c-9b79-e187d2040820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "\n",
        "subsample=[0.5,0.6,0.7,0.8,0.9,1]\n",
        "scale_pos_weight=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "\n",
        "# Create the random grid\n",
        "grid = {\n",
        "        'subsample': subsample,\n",
        "        'scale_pos_weight': scale_pos_weight,\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_search = GridSearchCV(estimator = xgb_model, param_grid = grid, cv = 5, scoring='roc_auc', verbose=2, n_jobs = -1)\n",
        "# Fit the model\n",
        "xgb_search.fit(X_no_id, y)\n",
        "# print results\n",
        "print(xgb_search.best_params_)\n",
        "print(xgb_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'scale_pos_weight': 0.8, 'subsample': 0.8}\n",
            "0.8590735440985217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "051R_DSAtUeq"
      },
      "source": [
        "#### Tuning everything with a smaller scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQgczBIZzikO",
        "outputId": "41df01f8-226c-4d66-dbfa-fd3f939a9fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4,max_depth=6,min_child_weight=6,gamma=4,scale_pos_weight=0.8,subsample=0.8, random_state=42)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eta=0.4, gamma=4,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=6, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=0.8, seed=None,\n",
              "              silent=None, subsample=0.8, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uQKXBnAtTvL",
        "outputId": "4deb7dbf-de25-44be-c58a-c2b589a1b3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "eta=[0.4,0.3,0.5]\n",
        "max_depth=[5,6,7,8,9,10]\n",
        "min_child_weight=[5,6,7]\n",
        "gamma=[3,4,5,6]\n",
        "subsample=[0.6,0.7,0.8,0.9]\n",
        "scale_pos_weight=[0.6,0.7,0.8,0.9]\n",
        "\n",
        "# Create the random grid\n",
        "grid = {'eta': eta,\n",
        "        'max_depth': max_depth,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'gamma': gamma,\n",
        "        'subsample': subsample,\n",
        "        'scale_pos_weight': scale_pos_weight,\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_random = RandomizedSearchCV(estimator = xgb_model, param_distributions = grid, n_iter = 100, scoring='roc_auc', cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "xgb_random.fit(X_no_id, y)\n",
        "# print results\n",
        "print(xgb_random.best_params_)\n",
        "print(xgb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'subsample': 0.9, 'scale_pos_weight': 0.7, 'min_child_weight': 7, 'max_depth': 10, 'gamma': 3, 'eta': 0.4}\n",
            "0.8612441721715811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCjVX6GwFt9C"
      },
      "source": [
        "### Tuning Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYz7C9ftFt9I",
        "outputId": "ec667c2a-3401-4f80-b715-4f1ed3615d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(random_state=42, eval_metric='AUC', verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f69d891fc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNH_cquXg-mn"
      },
      "source": [
        "# Grid Search\n",
        "grid = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
        "          'iterations':[250,100,500,1000],\n",
        "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
        "          'l2_leaf_reg':[3,1,5,10,100],\n",
        "          'border_count':[32,5,10,20,50,100,200],\n",
        "          'scale_pos_weight':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
        "          'thread_count':[4]\n",
        "          }\n",
        "# Random search of parameters\n",
        "cb_search = GridSearchCV(estimator = cb_model, param_grid = grid, cv = 5, scoring='roc_auc', verbose=2, n_jobs = -1)\n",
        "# Fit the model\n",
        "cb_search.fit(X_std, y)\n",
        "# print results\n",
        "print(cb_search.best_params_)\n",
        "print(cb_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xfstppAP4mn"
      },
      "source": [
        "### Tuning the Light GB Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03QJPnzwIqXU",
        "outputId": "b7605285-c1d8-42c1-b7de-caa079b9d2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id.dtypes != np.float)[0]\n",
        "lgb_model = LGBMClassifier(boosting_type='dart',cat_features=cat_feat,metric='auc',random_state=42, verbose=0)\n",
        "lgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='dart',\n",
              "               cat_features=array([ 0,  1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16, 17, 18,\n",
              "       19, 20, 21, 22, 23]),\n",
              "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
              "               learning_rate=0.1, max_depth=-1, metric='auc',\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
              "               verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dab7LlGbMC2M",
        "outputId": "73f604d5-bdc1-45f7-8380-3d434bb02716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "random_grid = {\n",
        "          \"max_depth\": [25,50, 75],\n",
        "          \"learning_rate\" : [0.01,0.05,0.1],\n",
        "          \"num_leaves\": [300,900,1200],\n",
        "          }\n",
        "\n",
        "# Random search of parameters\n",
        "lgb_random = RandomizedSearchCV(estimator = lgb_model, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, n_jobs=-1, random_state=42)\n",
        "# Fit the model\n",
        "lgb_random.fit(X_no_id, y)\n",
        "# print results\n",
        "print(lgb_random.best_params_)\n",
        "print(lgb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'num_leaves': 900, 'max_depth': 50, 'learning_rate': 0.05}\n",
            "0.9604470310146234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X8VKsAN9Suv"
      },
      "source": [
        "## S2-C:Tuned Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktdhydb4BjsK"
      },
      "source": [
        "### Random Forest with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYpH2BmsBjsO",
        "outputId": "af35e870-57ad-4c99-a8f3-b0a2b3044eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=20, bootstrap=False, n_estimators = 1500, n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=20, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=2, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOUVfU5aBjsb"
      },
      "source": [
        "test_probas = rf.predict_proba(test_std)\n",
        "rf_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "rf_solution.to_csv(\"rf_std2_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI1nfS1jBjse"
      },
      "source": [
        "Kaggle Score: 0.87501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWPZoChwKLb"
      },
      "source": [
        "### XGBoost with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jlbTv4Tvlyf"
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4,booster='dart',max_depth=9,min_child_weight=7,gamma=2,scale_pos_weight=0.8,subsample=0.8, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_no_id, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgluQZ3kv_9n"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_no_id)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std2_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbEOUn7gmJP"
      },
      "source": [
        "Kaggle Score: 0.87830"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhPvkAgTlMSX"
      },
      "source": [
        "### XGBoost with tuned parameters (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ygpXX3OlMSa"
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',max_depth=24,min_child_weight=1,gamma=9,scale_pos_weight=0.8,subsample=0.6, n_estimators=1500)\n",
        "xgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9bvRZ38lMSc"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_no_id)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_no_id_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-KRjOQblMSe"
      },
      "source": [
        "Kaggle Score: 0.87863"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rfxH7SaGE3V"
      },
      "source": [
        "### Catboost with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qXFwKTGGE3Z"
      },
      "source": [
        "cb_model = CatBoostClassifier(learning_rate=0.005, n_estimators=1500, max_depth=7, l2_leaf_reg=1, scale_pos_weight=0.7, random_state=42,task_type='GPU', verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VTPntDeGE3h"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_std_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U698E3PGE3k"
      },
      "source": [
        "Kaggle Score: 0.85171"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x1-f3R6qVNk"
      },
      "source": [
        "### Catboost with tuned parameters (3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7dYDeYMqVNm",
        "outputId": "e55c435e-b3a9-4646-a1f9-64d804d0bc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id.dtypes != np.float)[0]\n",
        "cb_model = CatBoostClassifier(cat_features=cat_feat,eval_metric='AUC', learning_rate=0.01, thread_count=4, n_estimators=1500, depth=3, l2_leaf_reg=100, scale_pos_weight=0.4, border_count=100, random_state=42, verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f69d6d6a1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJhtdY8pqVNu"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_noid_tuning3_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hOG119yqVNy"
      },
      "source": [
        "Kaggle Score: 0.92915"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMa4kLQyzLHL"
      },
      "source": [
        "### Catboost with tuned parameters (4)\n",
        "Testing the logloss metric due to the loss_function not having an AUC parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPyPvQZJzLHN"
      },
      "source": [
        "cb_model = CatBoostClassifier(loss_function='Logloss',eval_metric='AUC', learning_rate=0.01, thread_count=4, n_estimators=1500, depth=3, l2_leaf_reg=100, scale_pos_weight=0.4, border_count=100, random_state=42, verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NFel3CwzLHQ"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_noid_tuning4_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Kn6Zv8zLHR"
      },
      "source": [
        "Kaggle Score: 0.83829"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU7-dom3RXU1"
      },
      "source": [
        "### Light GB Model with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsENIxZTRXU2",
        "outputId": "1f43fbbf-741a-4430-9b69-ae7a7593d6cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id.dtypes != np.float)[0]\n",
        "lgb_model = LGBMClassifier(boosting_type='dart',cat_features=cat_feat,max_depth=50, num_leaves=900, learning_rate= 0.05, metric='auc',random_state=42, n_estimators=1500, verbose=0)\n",
        "lgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='dart',\n",
              "               cat_features=array([ 0,  1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16, 17, 18,\n",
              "       19, 20, 21, 22, 23]),\n",
              "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
              "               learning_rate=0.05, max_depth=50, metric='auc',\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=1500, n_jobs=-1, num_leaves=900, objective=None,\n",
              "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
              "               verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg_nV7r_RXU5"
      },
      "source": [
        "test_probas = lgb_model.predict_proba(test_no_id)\n",
        "lgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "lgb_solution.to_csv(\"lgb_model_noid_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNxqZy9cRXU6"
      },
      "source": [
        "Kaggle Score: 0.87897"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFQfeYGEQ6u"
      },
      "source": [
        "## S2-D: Stacking\n",
        "At this point, I tried to use stacking to improve my score. This decreased my score and I beleive this is due to the models overfitting. At this point, I realized I was not using the standardized data so I did not continue stacking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVaMF7EwcrEf"
      },
      "source": [
        "### Random Forest stacked with same Random Forest classified by Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keFZ6Uw7YYtj",
        "outputId": "37c1b87b-2ed6-45e6-84c3-5e34e6f9862a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=30, bootstrap=False, n_estimators = 1500, n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=30, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbImkO1Hau3S",
        "outputId": "1dc068ca-17e7-423c-e9ab-88ca7fb7567e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X_no_id_stacked=X_no_id.copy()\n",
        "rf1_preds = rf.predict(X_no_id)\n",
        "rf2_preds = rf.predict(X_no_id)\n",
        "rf1_series= pd.Series(rf1_preds)\n",
        "rf2_series= pd.Series(rf2_preds)\n",
        "X_std_stacked['rf1_preds'] = rf1_series\n",
        "X_std_stacked['rf2_preds'] = rf2_series\n",
        "stacked_rf = RandomForestClassifier(min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=30, bootstrap=False, n_estimators = 1500, n_jobs = -1,random_state = 42)\n",
        "stacked_rf.fit(X_no_id_stacked, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=30, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkV76-e3axeC"
      },
      "source": [
        "test_no_id_stacked=test_no_id.copy()\n",
        "rf1_test_preds = rf.predict(test_no_id)\n",
        "rf2_test_preds = rf.predict(test_no_id)\n",
        "rf1_test_series= pd.Series(rf1_test_preds)\n",
        "rf2_test_series= pd.Series(rf2_test_preds)\n",
        "test_no_id_stacked['rf1_test_preds'] = rf1_test_series\n",
        "test_no_id_stacked['rf2_test_preds'] = rf2_test_series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLp5rsDHccHg"
      },
      "source": [
        "test_pred = stacked_rf.predict(test_no_id_stacked)\n",
        "test_probas = stacked_rf.predict_proba(test_no_id_stacked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNZcYexea6fo"
      },
      "source": [
        "stacked_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "stacked_solution.to_csv(\"stacked_rf_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcIPes4MfVzm"
      },
      "source": [
        "Kaggle Score: 0.77292"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMxZXccRA_qw"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IseGSEOAXy1"
      },
      "source": [
        "# S3: Standardized Data\n",
        "After I realized my mistake, I fixed it and reran both the Random Forest models and the XGBoost models. I used multiple different parameter ranges and changes to see if I could improve the AUC score. Some of these changes helped, but most of the changes only improved the score by really small margins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HmIXxhACViM"
      },
      "source": [
        "## S3-A: No Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFPJtY2DCUkG"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4CcZEwQCUkJ"
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQTfg4ZCUkY"
      },
      "source": [
        "test_probas = rf.predict_proba(test_std)\n",
        "rf_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "rf_solution.to_csv(\"rf_std2_no_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3lQL35lCUkg"
      },
      "source": [
        "Kaggle Score: 0.86628"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdohL9WBrV8"
      },
      "source": [
        "## S3-B: Tuning Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjlGD0EUB-t-"
      },
      "source": [
        "### Tuning the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R9otWmhB-uR",
        "outputId": "c735ef75-b991-44ad-8a3e-3cf9b30ccead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZYw3ntB-uY",
        "outputId": "ab83241a-4189-4bd8-8347-f1692901b90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hypertuning the Random Forest Model\n",
        "\n",
        "# Number of trees in random forest\n",
        "#n_estimators = [500,1000,1500,2000]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {#'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap\n",
        "               }\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, scoring='roc_auc', cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_std, y)\n",
        "# print results\n",
        "print(rf_random.best_params_)\n",
        "print(rf_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   51.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
            "0.8615652409245795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqE_LMrJbp8N"
      },
      "source": [
        "### Tuning the XGBoost\n",
        "Due to the many variables to tune, I separated them into different sections by slowly building the model to get a quick range of where all the parameters were. Then I created a smaller grid search that looked at the smaller range for all the variables. I ran this multiple times with slightly different  ranges to get two or three different models to test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU8ae-fXzVSH",
        "outputId": "c6879972-ba34-4ad1-c1c7-2b36d3bb36fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zsch6SAzVSJ",
        "outputId": "dd2e61aa-13de-473c-9213-fbe27e21a065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "eta=[0.1,0.2]\n",
        "#n_estimators=[1500]\n",
        "max_depth=[10,14,16,18,20,22,24]\n",
        "min_child_weight=[1,3,5,6,7]\n",
        "gamma=[3,4,5,6,7,9]\n",
        "subsample=[0.5,0.6,0.7,0.8,0.9]\n",
        "scale_pos_weight=[0.6,0.7,0.8,0.9,1]\n",
        "max_delta_step=[1,2,3,4,5]\n",
        "\n",
        "# Create the random grid\n",
        "grid = {'eta': eta,\n",
        "        #'n_estimators': n_estimators,\n",
        "        'max_depth': max_depth,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'gamma': gamma,\n",
        "        'subsample': subsample,\n",
        "        'scale_pos_weight': scale_pos_weight,\n",
        "        'max_delta_step': max_delta_step\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_random = RandomizedSearchCV(estimator = xgb_model, param_distributions = grid, n_iter = 100, scoring='roc_auc', cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "xgb_random.fit(X_std, y)\n",
        "# print results\n",
        "print(xgb_random.best_params_)\n",
        "print(xgb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 12.3min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 22.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'subsample': 0.9, 'scale_pos_weight': 0.9, 'min_child_weight': 3, 'max_depth': 18, 'max_delta_step': 4, 'gamma': 5, 'eta': 0.2}\n",
            "0.8664444198414749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6eOv0yhC7AC",
        "outputId": "2ad7855b-22b6-4307-9b32-0e1de456c90d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_pred = rf.predict(X_std)\n",
        "y_probas = rf.predict_proba(X_std)\n",
        "print('Misclassified samples: %d' %(y != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y, y_pred))\n",
        "print('AUC score: %.2f' % roc_auc_score(y, y_probas[:, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 127\n",
            "Accuracy: 0.99\n",
            "AUC score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQE3_O-Am_wg"
      },
      "source": [
        "### Tuning Catboost\n",
        "Found a resource to retune some of the parameters for Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4RTDtDom_wj",
        "outputId": "a0548b81-e886-4c1b-b2ca-a63fd14bbb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(random_state=42,task_type='GPU', eval_metric='AUC', verbose=0)\n",
        "cb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f6e7f9eaef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6JHMaBPm_wr"
      },
      "source": [
        "# Hypertuning the Catboost model\n",
        "learning_rate = [0.03,0.001,0.01,0.1,0.2,0.3]\n",
        "iterations = [500,750,1000,1250,1500,1750,2000]\n",
        "max_depth = [1,2,3,4,5,6,7,8,9,10,12,14,16]\n",
        "l2_leaf_reg =[1,3,5,10,100]\n",
        "border_count =[5,10,20,30,50,100,200]\n",
        "scale_pos_weight=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "\n",
        "\n",
        "random_grid = {'learning_rate': learning_rate,\n",
        "              'iterations':iterations,\n",
        "              'max_depth': max_depth,\n",
        "              'l2_leaf_reg':l2_leaf_reg,\n",
        "               'border_count':border_count,\n",
        "              'scale_pos_weight': scale_pos_weight\n",
        "\n",
        "}\n",
        "\n",
        "# Random search of parameters\n",
        "cb_random = RandomizedSearchCV(estimator = cb_model, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42)\n",
        "# Fit the model\n",
        "cb_random.fit(X_std, y)\n",
        "# print results\n",
        "print(cb_random.best_params_)\n",
        "print(cb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWAK3FJ3BtpM"
      },
      "source": [
        "## S3-C: Tuned Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtiILJ-WZJjl"
      },
      "source": [
        "### Random Forest with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELXWLsQkC4Ti",
        "outputId": "af35e870-57ad-4c99-a8f3-b0a2b3044eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=20, bootstrap=False, n_estimators = 1500, n_jobs = -1,random_state = 42)\n",
        "rf.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=20, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=2, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLnIvxBPC85V"
      },
      "source": [
        "test_probas = rf.predict_proba(test_std)\n",
        "rf_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "rf_solution.to_csv(\"rf_std2_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H4apvE7gUyv"
      },
      "source": [
        "Kaggle Score: 0.87533"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZnyTegKYamy"
      },
      "source": [
        "### XGBoost with tuned parameters (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rGp2pYJYanA"
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4,booster='dart',max_depth=16,min_child_weight=7,gamma=3,scale_pos_weight=0.7,subsample=0.9, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4ZP79i5YanF"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_std)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std2_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78GByk_mYanI"
      },
      "source": [
        "Kaggle Score: 0.87797"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6F2mQAZoM9"
      },
      "source": [
        "### XGBoost with tuned parameters (3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpY13q6zZoM_"
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',max_depth=16, min_child_weight=7,gamma=3,scale_pos_weight=0.7,subsample=0.9, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjwMLXPUZoNH"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_std)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std2_tuning3_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuYyw4WDZoNN"
      },
      "source": [
        "Kaggle Score: 0.87831"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HwRuiyUj-FV"
      },
      "source": [
        "### XGBoost with tuned parameters (4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6hZmQ4Lj-FX"
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',max_depth=10, min_child_weight=1,gamma=3,scale_pos_weight=0.7,subsample=0.8, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWNa5xILj-FZ"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_std)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std_tuning4_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gyb1OQ7j-Fa"
      },
      "source": [
        "Kaggle Score: 0.87946"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u9QK5rQkQPu"
      },
      "source": [
        "### XGBoost with tuned parameters (5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unJPUa09kQPx"
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',max_depth=10, min_child_weight=2,gamma=2,scale_pos_weight=0.9,subsample=0.6, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raxDAczRkQP5"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_std)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std_tuning5_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiAzZQTqkQP-"
      },
      "source": [
        "Kaggle Score: 0.87684"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmvuRochzfBa"
      },
      "source": [
        "### XGBoost with tuned parameters (6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1GtUoUXzfBd"
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',max_depth=24, min_child_weight=1,gamma=3,scale_pos_weight=0.9,subsample=0.6, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrfpjECSzfBm"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_std)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std_tuning7_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skvGQ-LNzfBr"
      },
      "source": [
        "Kaggle Score: 0.87882"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmVvEo6Lk5Jx"
      },
      "source": [
        "### XGBoost with tuned parameters (7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tmU9eVvk5Jy"
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.4, booster='dart',max_depth=24, min_child_weight=1,gamma=3,scale_pos_weight=0.9,subsample=0.9, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl7kdvg3k5J1"
      },
      "source": [
        "test_probas = xgb_model.predict_proba(test_std)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_std_tuning8_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa6FsZ50k5J3"
      },
      "source": [
        "Kaggle Score: 0.87756"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzsTYRfUnGjD"
      },
      "source": [
        "### Catboost with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu6GHiwPnGjE"
      },
      "source": [
        "cb_model = CatBoostClassifier(learning_rate=0.01, iterations=1500, max_depth=9, l2_leaf_reg=3, scale_pos_weight=0.7, random_state=42,task_type='GPU', eval_metric='AUC', verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Q5m5mSnGjH"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_std2_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j6Sf73jnGjI"
      },
      "source": [
        "Kaggle Score: 0.87168"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN1zEZmlnShn"
      },
      "source": [
        "### Catboost with tuned parameters (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbbTDfF2nShp"
      },
      "source": [
        "cb_model = CatBoostClassifier(learning_rate=0.01, iterations=500, max_depth=9, l2_leaf_reg=3, scale_pos_weight=0.7, random_state=42,task_type='GPU', eval_metric='AUC', verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrHfcK6FnShu"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_std2_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPZwaWSInShz"
      },
      "source": [
        " Kaggle Score: 0.85613"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ZM_khvA_rZ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worJF5-jnLXR"
      },
      "source": [
        "# S4: Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xXo8cRBWv7w"
      },
      "source": [
        "## S4-A: XGBoost using Standardized Values-Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv5tIBsdRWJH"
      },
      "source": [
        "### Using XGBoost to drop features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDdUjoEop9JE",
        "outputId": "928ce077-2cff-4fd1-b41c-7c3487e98226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCe4_zodrJW4",
        "outputId": "ea51a54e-b761-484b-e1bf-ba3b0dab24a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Finding the feature importance\n",
        "importance = xgb_model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('f%0d, Score: %.5f' % (i+1,v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1, Score: 0.03690\n",
            "f2, Score: 0.00000\n",
            "f3, Score: 0.04208\n",
            "f4, Score: 0.05820\n",
            "f5, Score: 0.01866\n",
            "f6, Score: 0.01802\n",
            "f7, Score: 0.04918\n",
            "f8, Score: 0.06070\n",
            "f9, Score: 0.00000\n",
            "f10, Score: 0.03252\n",
            "f11, Score: 0.00000\n",
            "f12, Score: 0.02465\n",
            "f13, Score: 0.05682\n",
            "f14, Score: 0.28747\n",
            "f15, Score: 0.04232\n",
            "f16, Score: 0.03977\n",
            "f17, Score: 0.03821\n",
            "f18, Score: 0.00000\n",
            "f19, Score: 0.05056\n",
            "f20, Score: 0.02410\n",
            "f21, Score: 0.00000\n",
            "f22, Score: 0.06337\n",
            "f23, Score: 0.02433\n",
            "f24, Score: 0.03214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkhxr5Sir9Ol"
      },
      "source": [
        "#Selected f2,f5,f6,f9,f11,f18,f20 to drop because of its low importance\n",
        "all_data_drop = all_data.drop(['f2', 'f5', 'f6', 'f9', 'f11', 'f18', 'f20'], axis=1)\n",
        "feature_col_names=list(all_data_drop.columns)\n",
        "\n",
        "# Standarizing the data\n",
        "sc = StandardScaler()\n",
        "std_drop=sc.fit_transform(all_data_drop)\n",
        "\n",
        "#creating matrices for sklearn:\n",
        "X_std_drop = std_drop[:train.shape[0]]\n",
        "X_std_drop = pd.DataFrame(data=X_std_drop, columns=feature_col_names)\n",
        "test_std_drop = std_drop[train.shape[0]:]\n",
        "test_std_drop = pd.DataFrame(data=test_std_drop, columns=feature_col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U5oylveuGRT"
      },
      "source": [
        "### Tuning XGBoost after features dropped"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI63OZpKuGRU",
        "outputId": "bf119ef3-69f4-494b-fde6-b554481a4b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb_model = XGBClassifier(booster='dart',eval_metric='auc',random_state=42)\n",
        "xgb_model.fit(X_std_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
              "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHZoHY9WuGRW",
        "outputId": "6e827a7d-1f37-4c92-9b5c-0085df1a0b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Hypertuning the XGBoost\n",
        "eta=[0.03,0.001,0.01,0.1,0.2,0.3]\n",
        "n_estimators=[1000,1500,2000]\n",
        "max_depth=[1,7,5,6,10,14,16,18,20,22,24]\n",
        "min_child_weight=[1,3,5,6,7]\n",
        "gamma=[1,3,4,5,6,7,9]\n",
        "subsample=[0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "scale_pos_weight=[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "max_delta_step=[1,2,3,4,5]\n",
        "\n",
        "# Create the random grid\n",
        "grid = {'eta': eta,\n",
        "        'n_estimators': n_estimators,\n",
        "        'max_depth': max_depth,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'gamma': gamma,\n",
        "        'subsample': subsample,\n",
        "        'scale_pos_weight': scale_pos_weight,\n",
        "        'max_delta_step': max_delta_step\n",
        "               }\n",
        "\n",
        "# Random search of parameters\n",
        "xgb_random = RandomizedSearchCV(estimator = xgb_model, param_distributions = grid, n_iter = 10, scoring='roc_auc', cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "xgb_random.fit(X_std_drop, y)\n",
        "# print results\n",
        "print(xgb_random.best_params_)\n",
        "print(xgb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 165.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'subsample': 0.7, 'scale_pos_weight': 0.9, 'n_estimators': 2000, 'min_child_weight': 1, 'max_depth': 5, 'max_delta_step': 4, 'gamma': 4, 'eta': 0.03}\n",
            "0.8690272190853436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wssYm7s9up2v"
      },
      "source": [
        "### XGBoost with dropped features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sWs78Vsup2y",
        "outputId": "21cdc1fe-eb0f-4258-fa6c-ca61a4cc23dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.2,booster='dart',max_depth=18, min_child_weight=3,gamma=5,scale_pos_weight=0.9,subsample=0.9, max_delta_step=4, n_estimators=1500, random_state=42)\n",
        "xgb_model.fit(X_std_drop, y)\n",
        "y_pred = xgb_model.predict(X_std_drop)\n",
        "y_probas = xgb_model.predict_proba(X_std_drop)\n",
        "print('Misclassified samples: %d' %(y != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y, y_pred))\n",
        "print('AUC score: %.2f' % roc_auc_score(y, y_probas[:, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 319\n",
            "Accuracy: 0.98\n",
            "AUC score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emS5e6L1up28"
      },
      "source": [
        "test_pred = xgb_model.predict(test_std_drop)\n",
        "test_probas = xgb_model.predict_proba(test_std_drop)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_fd_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjG5Iy5rup2-"
      },
      "source": [
        "Kaggle Score: 0.88428\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl9yCbnyVuC4"
      },
      "source": [
        "### XGBoost with dropped features (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB-ozD8OVuC6",
        "outputId": "134b04cb-5e32-48b3-feef-f31eaf2f3254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "xgb_model = XGBClassifier(eta=0.03,booster='dart',max_depth=5, min_child_weight=1,gamma=4,scale_pos_weight=0.9,subsample=0.7, max_delta_step=4, eval_metric='auc', n_estimators=2000, random_state=42)\n",
        "xgb_model.fit(X_std_drop, y)\n",
        "y_pred = xgb_model.predict(X_std_drop)\n",
        "y_probas = xgb_model.predict_proba(X_std_drop)\n",
        "print('Misclassified samples: %d' %(y != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y, y_pred))\n",
        "print('AUC score: %.2f' % roc_auc_score(y, y_probas[:, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 348\n",
            "Accuracy: 0.98\n",
            "AUC score: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrvJtr7jVuDC"
      },
      "source": [
        "test_pred = xgb_model.predict(test_std_drop)\n",
        "test_probas = xgb_model.predict_proba(test_std_drop)\n",
        "xgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "xgb_solution.to_csv(\"xgb_model_fd2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrJOyeVQVuDH"
      },
      "source": [
        "Kaggle Score: 0.88262\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE1c7IFHO_6X"
      },
      "source": [
        "## S4-B: XGBoost stacked with XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nMH4r7lPIl1"
      },
      "source": [
        "#Selected f2,f5,f6,f9,f11,f18,f20 to drop because of its low importance\n",
        "all_data_drop = all_data.drop(['f2', 'f5', 'f6', 'f9', 'f11', 'f18', 'f20'], axis=1)\n",
        "feature_col_names=list(all_data_drop.columns)\n",
        "\n",
        "# Standarizing the data\n",
        "sc = StandardScaler()\n",
        "std_drop=sc.fit_transform(all_data_drop)\n",
        "\n",
        "#creating matrices for sklearn:\n",
        "X_std_drop = std_drop[:train.shape[0]]\n",
        "X_std_drop = pd.DataFrame(data=X_std_drop, columns=feature_col_names)\n",
        "test_std_drop = std_drop[train.shape[0]:]\n",
        "test_std_drop = pd.DataFrame(data=test_std_drop, columns=feature_col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcaHv3QHO_6Y",
        "outputId": "e21a819b-72d0-4e03-ca5a-d298b4aafaa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "xgb = XGBClassifier(eta=0.2,booster='dart',max_depth=18, min_child_weight=3,gamma=5,scale_pos_weight=0.9,subsample=0.9, max_delta_step=4, n_estimators=1500, random_state=42)\n",
        "xgb.fit(X_std_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eta=0.2, gamma=5,\n",
              "              learning_rate=0.1, max_delta_step=4, max_depth=18,\n",
              "              min_child_weight=3, missing=None, n_estimators=1500, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=0.9, seed=None,\n",
              "              silent=None, subsample=0.9, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBhtmCSAO_6a",
        "outputId": "40934a0b-4a90-450f-f665-54d77c50f09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_std_stacked=X_std_drop.copy()\n",
        "xgb_preds = xgb.predict(X_std_drop)\n",
        "xgb_series= pd.Series(xgb_preds)\n",
        "X_std_stacked['xgb_preds'] = xgb_series\n",
        "stacked_xgb = XGBClassifier(eta=0.2,booster='dart',max_depth=18, min_child_weight=3,gamma=5,scale_pos_weight=0.9,subsample=0.9, max_delta_step=4, n_estimators=1500, random_state=42)\n",
        "stacked_xgb.fit(X_std_stacked, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eta=0.2, gamma=5,\n",
              "              learning_rate=0.1, max_delta_step=4, max_depth=18,\n",
              "              min_child_weight=3, missing=None, n_estimators=1500, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=0.9, seed=None,\n",
              "              silent=None, subsample=0.9, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYB9ZJnrO_6b"
      },
      "source": [
        "test_std_stacked=test_std_drop.copy()\n",
        "xgb_test_preds = xgb.predict(test_std_drop)\n",
        "xgb_test_series= pd.Series(xgb_test_preds)\n",
        "test_std_stacked['xgb_preds'] = xgb_test_series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gvm7kRFO_6c"
      },
      "source": [
        "test_pred = stacked_xgb.predict(test_std_stacked)\n",
        "test_probas = stacked_xgb.predict_proba(test_std_stacked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igA-HLohO_6e"
      },
      "source": [
        "stacked_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "stacked_solution.to_csv(\"stacked_xgb_fd_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S79xstHzO_6f"
      },
      "source": [
        "Kaggle Score: 0.83729"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU9HepnQOhLb"
      },
      "source": [
        "## S4-C: Catboost using Standardized Values-Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbo88KqPPqKe"
      },
      "source": [
        "### Using Catboost to drop features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7NjGIomOhLc",
        "outputId": "54ce0cbd-43b9-489b-b6af-b53b33c810ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(random_state=42,task_type='GPU', verbose=0)\n",
        "cb_model.fit(X_std, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fe15a0f06d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32F0haR9PWio",
        "outputId": "5f958292-5f46-4af9-f14b-db4fe6936671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Finding the feature importance\n",
        "importance = cb_model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('f%0d, Score: %.5f' % (i+1,v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1, Score: 2.98164\n",
            "f2, Score: 0.13857\n",
            "f3, Score: 0.56606\n",
            "f4, Score: 5.06800\n",
            "f5, Score: 0.27503\n",
            "f6, Score: 0.12787\n",
            "f7, Score: 1.94005\n",
            "f8, Score: 4.33906\n",
            "f9, Score: 0.06631\n",
            "f10, Score: 0.46247\n",
            "f11, Score: 0.02798\n",
            "f12, Score: 0.58186\n",
            "f13, Score: 2.63522\n",
            "f14, Score: 64.65835\n",
            "f15, Score: 5.03643\n",
            "f16, Score: 3.97784\n",
            "f17, Score: 3.49381\n",
            "f18, Score: 0.10235\n",
            "f19, Score: 1.89136\n",
            "f20, Score: 0.24434\n",
            "f21, Score: 0.08251\n",
            "f22, Score: 0.12418\n",
            "f23, Score: 0.84710\n",
            "f24, Score: 0.33161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsODatW-PbX5"
      },
      "source": [
        "#Selected f2,f6,f9,f11,f18,f21,f22 to drop because of its low importance\n",
        "all_data_drop = all_data.drop(['f2', 'f6', 'f9', 'f11', 'f18', 'f21','f22'], axis=1)\n",
        "feature_col_names=list(all_data_drop.columns)\n",
        "\n",
        "# Standarizing the data\n",
        "sc = StandardScaler()\n",
        "std_drop=sc.fit_transform(all_data_drop)\n",
        "\n",
        "#creating matrices for sklearn:\n",
        "X_std_drop = std_drop[:train.shape[0]]\n",
        "X_std_drop = pd.DataFrame(data=X_std_drop, columns=feature_col_names)\n",
        "test_std_drop = std_drop[train.shape[0]:]\n",
        "test_std_drop = pd.DataFrame(data=test_std_drop, columns=feature_col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JtugSrsOhLc"
      },
      "source": [
        "### Tuning Catboost after dropping features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-GjU3hZQc12",
        "outputId": "61d6625a-ffd1-42c3-a5f4-6b36cc2c55f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(random_state=42,task_type='GPU', verbose=0)\n",
        "cb_model.fit(X_std_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fe1508e7080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ep2JZbuOhLf"
      },
      "source": [
        "# Hypertuning the Catboost model\n",
        "learning_rate = [0.4,0.3,0.2,0.1,0.005]\n",
        "#n_estimators = [500,1000,1500]\n",
        "max_depth = [1,2,3,4,5,6,7,8,9,10]\n",
        "l2_leaf_reg =[1,3,5,10,100]\n",
        "scale_pos_weight=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "\n",
        "\n",
        "random_grid = {'learning_rate': learning_rate,\n",
        "              #'n_estimators':n_estimators,\n",
        "              'max_depth': max_depth,\n",
        "              'l2_leaf_reg':l2_leaf_reg,\n",
        "              'scale_pos_weight': scale_pos_weight\n",
        "\n",
        "}\n",
        "\n",
        "# Random search of parameters\n",
        "cb_random = RandomizedSearchCV(estimator = cb_model, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42)\n",
        "# Fit the model\n",
        "cb_random.fit(X_std_drop, y)\n",
        "# print results\n",
        "print(cb_random.best_params_)\n",
        "print(cb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V5aDl07OhLj"
      },
      "source": [
        "### Catboost with dropped features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lsHyeLdOhLk",
        "outputId": "4baa5c63-28fb-4414-e3e2-d5b3e3cd4936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(learning_rate=0.005, n_estimators=1500, max_depth=7, l2_leaf_reg=1, scale_pos_weight=0.7, random_state=42,task_type='GPU', verbose=0)\n",
        "cb_model.fit(X_std_drop, y)\n",
        "y_pred = cb_model.predict(X_std_drop)\n",
        "y_probas = cb_model.predict_proba(X_std_drop)\n",
        "print('Misclassified samples: %d' %(y != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y, y_pred))\n",
        "print('AUC score: %.2f' % roc_auc_score(y, y_probas[:, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 653\n",
            "Accuracy: 0.96\n",
            "AUC score: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZtG5wUIOhLl"
      },
      "source": [
        "test_pred = cb_model.predict(test_std_drop)\n",
        "test_probas = cb_model.predict_proba(test_std_drop)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_fd_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFZe38mZOhLm"
      },
      "source": [
        "Kaggle Score: 0.85791"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsBf4HkPQuuE"
      },
      "source": [
        "## S4-D: Catboost using Data Values with No Id Column-Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrA4LDeAQqXh"
      },
      "source": [
        "### Using Catboost to drop features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaCO2m-0QqXi",
        "outputId": "8e885869-40bf-480e-e5f9-b736dc86ef83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(random_state=42, verbose=0)\n",
        "cb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f7db6959780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTfvrDceQqXm",
        "outputId": "33618717-1295-4a9f-b625-677ee9f3508f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Finding the feature importance\n",
        "importance = cb_model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('f%0d, Score: %.5f' % (i+1,v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1, Score: 5.46178\n",
            "f2, Score: 0.27888\n",
            "f3, Score: 1.35335\n",
            "f4, Score: 6.03119\n",
            "f5, Score: 0.18184\n",
            "f6, Score: 0.21357\n",
            "f7, Score: 2.79626\n",
            "f8, Score: 5.71512\n",
            "f9, Score: 0.06048\n",
            "f10, Score: 1.08223\n",
            "f11, Score: 0.21621\n",
            "f12, Score: 1.44704\n",
            "f13, Score: 3.53180\n",
            "f14, Score: 47.39967\n",
            "f15, Score: 6.82154\n",
            "f16, Score: 6.27292\n",
            "f17, Score: 4.54204\n",
            "f18, Score: 0.25579\n",
            "f19, Score: 2.97781\n",
            "f20, Score: 0.23034\n",
            "f21, Score: 0.21506\n",
            "f22, Score: 0.46469\n",
            "f23, Score: 2.06534\n",
            "f24, Score: 0.38506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS2hIz9fQqXn"
      },
      "source": [
        "#Selected f2,f5,f6,f9,f11,f18,f20,f21 to drop because of its low importance\n",
        "all_data_drop = all_data.drop(['f2', 'f5','f6', 'f9', 'f11', 'f18', 'f20','f21'], axis=1)\n",
        "feature_col_names=list(all_data_drop.columns)\n",
        "X_no_id_drop= all_data_drop[:train.shape[0]]\n",
        "test_no_id_drop = all_data_drop[train.shape[0]:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rw8pkDsSf5N"
      },
      "source": [
        "### Tuning Catboost after dropping features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLk38yPxSf5Q",
        "outputId": "ef63c655-558b-42f1-8343-5adf67161f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(random_state=42,eval_metric='AUC', verbose=0)\n",
        "cb_model.fit(X_no_id_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fd9e20d1b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHPpIQyo7eZ2"
      },
      "source": [
        "random_grid = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
        "          'iterations':[250,100,500,1000],\n",
        "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
        "          'l2_leaf_reg':[3,1,5,10,100],\n",
        "          'border_count':[32,5,10,20,50,100,200],\n",
        "          'scale_pos_weight':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
        "          'thread_count':[4]\n",
        "          }\n",
        "\n",
        "# Random search of parameters\n",
        "cb_random = RandomizedSearchCV(estimator = cb_model, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42)\n",
        "# Fit the model\n",
        "cb_random.fit(X_no_id_drop, y)\n",
        "# print results\n",
        "print(cb_random.best_params_)\n",
        "print(cb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz_AoDGfS53S"
      },
      "source": [
        "### Catboost tuned with dropped features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5GUVHgcS53T",
        "outputId": "d03acadc-9bed-4509-a615-fa73054f9ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cb_model = CatBoostClassifier(eval_metric='AUC', learning_rate=0.01, thread_count=4, n_estimators=1500, depth=3, l2_leaf_reg=100, scale_pos_weight=0.4, border_count=100, random_state=42, verbose=0)\n",
        "cb_model.fit(X_no_id_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fd9df973278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxcAuIuQS53X"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id_drop)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_noid_fd_tuned_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhUxR-THS53a"
      },
      "source": [
        "Kaggle Score: 0.83829"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQOeMwD1SwTZ"
      },
      "source": [
        "### Catboost tuned with dropped features (2)\n",
        "Best Score: Used an additional parameter with the tuned parameters from before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyjVzQjySwTd",
        "outputId": "2c8b6774-d723-4c9c-b097-134d776d1b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id_drop.dtypes != np.float)[0]\n",
        "cb_model = CatBoostClassifier(cat_features=cat_feat,eval_metric='AUC', learning_rate=0.01, thread_count=4, n_estimators=1500, depth=3, l2_leaf_reg=100, scale_pos_weight=0.4, border_count=100, random_state=42, verbose=0)\n",
        "cb_model.fit(X_no_id_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fd9de81f550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ_TPiGvSwTn"
      },
      "source": [
        "test_probas = cb_model.predict_proba(test_no_id_drop)\n",
        "cb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "cb_solution.to_csv(\"cb_model_noid_fd_tuning2_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlNcszu2SwTr"
      },
      "source": [
        "Kaggle Score: 0.92947"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEiF_bdbRxcM"
      },
      "source": [
        "## S4-E:  Light GB Model using Data Values with No Id Column-Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ooDQpznR7-Z"
      },
      "source": [
        "### Using Light GB to drop features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Gic-tNR7-b",
        "outputId": "2e41f9ca-4922-4b82-f65a-a3938925ccff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id.dtypes != np.float)[0]\n",
        "lgb_model = LGBMClassifier(boosting_type='dart',cat_features=cat_feat,metric='auc',random_state=42, n_estimators=1500, verbose=0)\n",
        "lgb_model.fit(X_no_id, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='dart',\n",
              "               cat_features=array([ 0,  1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16, 17, 18,\n",
              "       19, 20, 21, 22, 23]),\n",
              "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
              "               learning_rate=0.1, max_depth=-1, metric='auc',\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=1500, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
              "               verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFHdUVCJR7-j",
        "outputId": "092dc900-c653-4e6c-b460-10fbf5dcedbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Finding the feature importance\n",
        "importance = lgb_model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('f%0d, Score: %.5f' % (i+1,v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1, Score: 5458.00000\n",
            "f2, Score: 118.00000\n",
            "f3, Score: 1443.00000\n",
            "f4, Score: 3804.00000\n",
            "f5, Score: 91.00000\n",
            "f6, Score: 82.00000\n",
            "f7, Score: 1460.00000\n",
            "f8, Score: 3819.00000\n",
            "f9, Score: 64.00000\n",
            "f10, Score: 1172.00000\n",
            "f11, Score: 90.00000\n",
            "f12, Score: 1367.00000\n",
            "f13, Score: 2830.00000\n",
            "f14, Score: 6198.00000\n",
            "f15, Score: 5751.00000\n",
            "f16, Score: 4688.00000\n",
            "f17, Score: 2412.00000\n",
            "f18, Score: 46.00000\n",
            "f19, Score: 1197.00000\n",
            "f20, Score: 64.00000\n",
            "f21, Score: 127.00000\n",
            "f22, Score: 114.00000\n",
            "f23, Score: 2436.00000\n",
            "f24, Score: 169.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW5WVfRaR7-x"
      },
      "source": [
        "#Selected f2,f5,f6,f9,f11,f18,f20,f21, f22, f24 to drop because of its low importance\n",
        "all_data_drop = all_data.drop(['f2', 'f5','f6', 'f9', 'f11', 'f18', 'f20','f21','f22','f24'], axis=1)\n",
        "feature_col_names=list(all_data_drop.columns)\n",
        "X_no_id_drop= all_data_drop[:train.shape[0]]\n",
        "test_no_id_drop = all_data_drop[train.shape[0]:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QubpRf_KRoxB"
      },
      "source": [
        "### Tuning the Light GB Model after dropping features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9Ias6VwRoxD",
        "outputId": "54373640-fb8b-4da5-b11e-b38772fb5043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id_drop.dtypes != np.float)[0]\n",
        "lgb_model = LGBMClassifier(boosting_type='dart',cat_features=cat_feat,metric='auc',random_state=42, verbose=0)\n",
        "lgb_model.fit(X_no_id_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='dart',\n",
              "               cat_features=array([ 0,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13]),\n",
              "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
              "               learning_rate=0.1, max_depth=-1, metric='auc',\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
              "               verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPzaOk6KRoxL",
        "outputId": "f3038bca-af20-41d1-e2dd-839a9dfe9813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "random_grid = {\n",
        "          \"max_depth\": [25,50, 75],\n",
        "          \"learning_rate\" : [0.01,0.05,0.1],\n",
        "          \"num_leaves\": [300,900,1200],\n",
        "          }\n",
        "\n",
        "# Random search of parameters\n",
        "lgb_random = RandomizedSearchCV(estimator = lgb_model, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, n_jobs=-1, random_state=42)\n",
        "# Fit the model\n",
        "lgb_random.fit(X_no_id_drop, y)\n",
        "# print results\n",
        "print(lgb_random.best_params_)\n",
        "print(lgb_random.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'num_leaves': 300, 'max_depth': 25, 'learning_rate': 0.05}\n",
            "0.9604470496444864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NbxaQOZRq8g"
      },
      "source": [
        "### Light GB Model with dropped features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WulDdtjJRq8j",
        "outputId": "51fe3161-3f76-40b4-971a-d9f07689ed3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "cat_feat = np.where(X_no_id_drop.dtypes != np.float)[0]\n",
        "lgb_model = LGBMClassifier(boosting_type='dart',max_depth=25, num_leaves=300, learning_rate= 0.05, cat_features=cat_feat,metric='auc',random_state=42, n_estimators=1500, verbose=0)\n",
        "lgb_model.fit(X_no_id_drop, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='dart',\n",
              "               cat_features=array([ 0,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13]),\n",
              "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
              "               learning_rate=0.05, max_depth=25, metric='auc',\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=1500, n_jobs=-1, num_leaves=300, objective=None,\n",
              "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
              "               verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T-eoYNQRq8u"
      },
      "source": [
        "test_probas = lgb_model.predict_proba(test_no_id_drop)\n",
        "lgb_solution = pd.DataFrame({'Id': test.Id, 'Y' : test_probas[:, 1]})\n",
        "lgb_solution.to_csv(\"lgb_model_fd_tuning_sol.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkj_m7wERq8y"
      },
      "source": [
        "Kaggle Score: 0.87865"
      ]
    }
  ]
}